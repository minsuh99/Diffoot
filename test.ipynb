{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Data Loading---\n",
      "Skip organize_and_process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Loading...: 100%|██████████| 6/6 [02:19<00:00, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Data Load!---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\" # For reproducability\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from models.lstm_model import DefenseTrajectoryPredictor\n",
    "from make_dataset import MultiMatchSoccerDataset, organize_and_process\n",
    "from utils.utils import set_seed, plot_trajectories_on_pitch\n",
    "from utils.data_utils import split_dataset_indices, custom_collate_fn\n",
    "\n",
    "# 0. Set seed\n",
    "set_seed(42)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)  \n",
    "\n",
    "# 1. Hyperparameter Setting\n",
    "# raw_data_path = \"Download raw file path\"\n",
    "raw_data_path = \"idsse-data\"\n",
    "data_save_path = \"match_data\"\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "# epochs = 100\n",
    "epochs=1\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Data Loading\n",
    "print(\"---Data Loading---\")\n",
    "\n",
    "if not os.path.exists(data_save_path) or len(os.listdir(data_save_path)) == 0:\n",
    "    organize_and_process(raw_data_path, data_save_path)\n",
    "else:\n",
    "    print(\"Skip organize_and_process\")\n",
    "    \n",
    "dataset = MultiMatchSoccerDataset(data_root=data_save_path, use_condition_graph=False)\n",
    "train_idx, test_idx, _, _ = split_dataset_indices(dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    Subset(dataset, train_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    "    )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    Subset(dataset, test_idx),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "print(\"---Data Load!---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Define\n",
    "model = DefenseTrajectoryPredictor().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [05:17<00:00, 317.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.145503, Current LR: 0.000100\n",
      "---Train finished!---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Train\n",
    "print(\"--- Train ---\")\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        condition = batch['condition'].to(device)  # [B, T, 158]\n",
    "        target = batch['target'].to(device)        # [B, T, 22]\n",
    "        pred = model(condition)                    # [B, T, 22]\n",
    "\n",
    "        # 선수별 경로 MSE 구한 후 평균\n",
    "        pred = pred.view(pred.shape[0], pred.shape[1], 11, 2)      # [B, T, 11, 2]\n",
    "        target = target.view(target.shape[0], target.shape[1], 11, 2)  # [B, T, 11, 2]\n",
    "\n",
    "        mse = ((pred - target) ** 2).mean(dim=(1, 2, 3))  # [B]\n",
    "        loss = mse.mean()  # scalar\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    tqdm.write(f\"[Epoch {epoch}] Train Loss: {avg_loss:.6f}, Current LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "print(\"---Train finished!---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [01:17<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inference] ADE: 24.0173 | FDE: 25.2674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Inference ＆ Visualization\n",
    "print(\"--- Inference ---\")\n",
    "model.eval()\n",
    "all_ade = []\n",
    "all_fde = []\n",
    "\n",
    "visualize_samples = 5\n",
    "visualization_done = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        # Inference\n",
    "        condition = batch['condition'].to(device)\n",
    "        target = batch['target'].to(device)  # [B, T, 22]\n",
    "        pred = model(condition)              # [B, T, 22]\n",
    "\n",
    "        pred = pred.view(pred.shape[0], pred.shape[1], 11, 2)      # [B, T, 11, 2]\n",
    "        target = target.view(target.shape[0], target.shape[1], 11, 2)\n",
    "\n",
    "        # Denormalize\n",
    "        x_scales = torch.tensor([s[0] for s in batch[\"pitch_scale\"]], device=device).view(-1, 1, 1)\n",
    "        y_scales = torch.tensor([s[1] for s in batch[\"pitch_scale\"]], device=device).view(-1, 1, 1)\n",
    "\n",
    "        pred = pred.clone()\n",
    "        target = target.clone()\n",
    "\n",
    "        pred[..., 0] *= x_scales\n",
    "        pred[..., 1] *= y_scales\n",
    "        target[..., 0] *= x_scales\n",
    "        target[..., 1] *= y_scales\n",
    "        \n",
    "        # Player-wise ADE\n",
    "        ade = ((pred - target) ** 2).sum(-1).sqrt().mean(1).mean(1)  # [B]\n",
    "        all_ade.extend(ade.cpu().numpy())\n",
    "\n",
    "        # Player-wise FDE\n",
    "        fde = ((pred[:, -1] - target[:, -1]) ** 2).sum(-1).sqrt().mean(1)  # [B]\n",
    "        all_fde.extend(fde.cpu().numpy())\n",
    "        \n",
    "        # Visualization\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        if not visualization_done:\n",
    "            B = pred.shape[0]\n",
    "            for i in range(min(B, visualize_samples)):\n",
    "                others = batch[\"other\"][i].view(-1, 12, 2).cpu()\n",
    "                target_vis = target[i].cpu()\n",
    "                pred_vis = pred[i].cpu()\n",
    "                pitch_scale = batch[\"pitch_scale\"][i]\n",
    "                \n",
    "                save_path = f\"results/LSTM_sample_{i:02d}.png\"\n",
    "                plot_trajectories_on_pitch(others, target_vis, pred_vis, pitch_scale, save_path=save_path)\n",
    "\n",
    "            visualization_done = True\n",
    "        \n",
    "avg_ade = np.mean(all_ade)\n",
    "avg_fde = np.mean(all_fde)\n",
    "print(f\"[Inference] ADE: {avg_ade:.4f} | FDE: {avg_fde:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '█' (U+2588) (1647275299.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    100%|██████████| 1/1 [05:17<00:00, 317.12s/it][Epoch 1] Train Loss: 0.141158, Current LR: 0.000100\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '█' (U+2588)\n"
     ]
    }
   ],
   "source": [
    "--- Train ---\n",
    "100%|██████████| 1/1 [05:17<00:00, 317.12s/it][Epoch 1] Train Loss: 0.141158, Current LR: 0.000100\n",
    "---Train finished!---\n",
    "\n",
    "--- Inference ---\n",
    "100%|██████████| 40/40 [01:11<00:00,  1.79s/it][Inference] ADE: 22.5559 | FDE: 23.2545"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoccerTraj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
