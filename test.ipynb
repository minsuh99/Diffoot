{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method('forkserver', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Data Loading---\n",
      "Skip organize_and_process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Matches: 100%|██████████| 6/6 [00:41<00:00,  6.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Data Load!---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/SoccerTraj/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from models.diff_modules import diff_CSDI\n",
    "from models.diff_model import DiffusionTrajectoryModel\n",
    "from models.encoder import InteractionGraphEncoder\n",
    "from make_dataset import MultiMatchSoccerDataset, organize_and_process\n",
    "from utils.utils import set_evertyhing, worker_init_fn, generator, plot_trajectories_on_pitch\n",
    "from utils.data_utils import split_dataset_indices, custom_collate_fn\n",
    "from utils.graph_utils import build_graph_sequence_from_condition\n",
    "\n",
    "# 1. Hyperparameter Setting\n",
    "# raw_data_path = \"Download raw file path\"\n",
    "raw_data_path = \"idsse-data\"\n",
    "data_save_path = \"match_data\"\n",
    "batch_size = 32\n",
    "num_workers = 8\n",
    "epochs = 50\n",
    "learning_rate = 2e-4\n",
    "num_samples = 5\n",
    "SEED = 42\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]   = \"1\"\n",
    "\n",
    "set_evertyhing(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Data Loading\n",
    "print(\"---Data Loading---\")\n",
    "if not os.path.exists(data_save_path) or len(os.listdir(data_save_path)) == 0:\n",
    "    organize_and_process(raw_data_path, data_save_path)\n",
    "else:\n",
    "    print(\"Skip organize_and_process\")\n",
    "\n",
    "dataset = MultiMatchSoccerDataset(data_root=data_save_path)\n",
    "train_idx, val_idx, test_idx = split_dataset_indices(dataset, val_ratio=1/6, test_ratio=1/6, random_seed=SEED)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    Subset(dataset, train_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    generator=generator(SEED)\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    Subset(dataset, val_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    Subset(dataset, test_idx),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    worker_init_fn=worker_init_fn\n",
    ")\n",
    "\n",
    "print(\"---Data Load!---\")\n",
    "\n",
    "# 3. Model Define\n",
    "# Extract node feature dimension\n",
    "sample = dataset[0]\n",
    "graph = build_graph_sequence_from_condition({\n",
    "    \"condition\": sample[\"condition\"],\n",
    "    \"condition_columns\": sample[\"condition_columns\"],\n",
    "    \"pitch_scale\": sample[\"pitch_scale\"]\n",
    "}).to(device)\n",
    "in_dim = graph['Node'].x.size(1)\n",
    "\n",
    "csdi_config = {\n",
    "    \"num_steps\": 500,\n",
    "    \"channels\": 256,\n",
    "    \"diffusion_embedding_dim\": 128,\n",
    "    \"nheads\": 4,\n",
    "    \"layers\": 10,\n",
    "    \"side_dim\": 128\n",
    "}\n",
    "\n",
    "graph_encoder = InteractionGraphEncoder(in_dim=in_dim, hidden_dim=128, out_dim=128, heads = 2).to(device)\n",
    "denoiser = diff_CSDI(csdi_config)\n",
    "model = DiffusionTrajectoryModel(denoiser, num_steps=csdi_config[\"num_steps\"]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e97450a35b43e5b16b0fda034914c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3499c0ba0a84c5aa4b7ee0de036afcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [01:03<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8ab6d5068e43aeb0d8fb5116ed3eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [01:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1]\n",
      "Cost: 0.822846 | Noise Loss: 0.238871 | Player Loss: 0.583975 | LR: 0.000200\n",
      "Val Loss: 0.147384 | Noise: 0.084494 | Player: 0.062890 | Model Update: Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74e252205934d848b600c9c65d46608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a71883d8624ce5a3e3e57ae70e1264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2]\n",
      "Cost: 0.124261 | Noise Loss: 0.071221 | Player Loss: 0.053040 | LR: 0.000200\n",
      "Val Loss: 0.092819 | Noise: 0.055013 | Player: 0.037807 | Model Update: Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b326e8456b4d8ea4cb6e62645496bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e899d72224f490f928b480b59b91ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3]\n",
      "Cost: 0.091820 | Noise Loss: 0.051584 | Player Loss: 0.040236 | LR: 0.000200\n",
      "Val Loss: 0.079983 | Noise: 0.046108 | Player: 0.033875 | Model Update: Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ae3659a32e490a832f40e36466bc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a3698ab060411bba326c2c549b7dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4]\n",
      "Cost: 0.079736 | Noise Loss: 0.045406 | Player Loss: 0.034329 | LR: 0.000200\n",
      "Val Loss: 0.087863 | Noise: 0.045283 | Player: 0.042580 | Model Update: No Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e112d8c7563431f8fee1252533c4470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b77bbebab624c1ab0bccd2a666669be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5]\n",
      "Cost: 0.071387 | Noise Loss: 0.041479 | Player Loss: 0.029907 | LR: 0.000200\n",
      "Val Loss: 0.064880 | Noise: 0.038052 | Player: 0.026828 | Model Update: Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff5419297d046ebb84ab9ef99c13b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6788b7873e9c4ce3b4465e5dce392082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6]\n",
      "Cost: 0.069560 | Noise Loss: 0.039634 | Player Loss: 0.029927 | LR: 0.000200\n",
      "Val Loss: 0.058964 | Noise: 0.035998 | Player: 0.022967 | Model Update: Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec9d85a57ad46d6bd06baff4bcabc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbc4ad1328643e88dddd5470cc23d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7]\n",
      "Cost: 0.062752 | Noise Loss: 0.036762 | Player Loss: 0.025990 | LR: 0.000200\n",
      "Val Loss: 0.059105 | Noise: 0.034454 | Player: 0.024651 | Model Update: No Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4382eb5b6e45f9b4a2b61acb778f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e339d523e8d480e9ef3bd67e4557b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8]\n",
      "Cost: 0.059177 | Noise Loss: 0.036224 | Player Loss: 0.022953 | LR: 0.000200\n",
      "Val Loss: 0.063572 | Noise: 0.036462 | Player: 0.027110 | Model Update: No Update\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69de1dc8a5a34ef6918b064ebf9c9040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Training...:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Train\n",
    "best_state_dict = None\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses   = []\n",
    "flag = False\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1), desc=\"Training...\"):\n",
    "    model.train()\n",
    "    train_noise_loss = 0\n",
    "    train_player_loss = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc = \"Batch Training...\"):\n",
    "        B, T, _ = batch[\"condition\"].shape\n",
    "        target = batch[\"target\"].to(device).view(B, T, 11, 2)  # [B, T, 11, 2]\n",
    "        H = graph_encoder(batch[\"graph\"].to(device))                      # [B, 128]\n",
    "        cond_H = H.unsqueeze(-1).unsqueeze(-1).expand(-1, H.size(1), 11, T)\n",
    "\n",
    "        # Preparing Self-conditioning data\n",
    "        if torch.rand(1, device=device) < 0.5:\n",
    "            s = torch.zeros_like(target)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                t = torch.randint(0, model.num_steps, (target.size(0),), device=device)\n",
    "                x_t, noise = model.q_sample(target, t)\n",
    "                x_t = x_t.permute(0,3,2,1)\n",
    "                eps_pred1 = model.model(x_t, t, cond_H, self_cond=None)\n",
    "                a_hat = model.alpha_hat.to(device)[t].view(-1,1,1,1)\n",
    "                x0_hat = (x_t - (1 - a_hat).sqrt() * eps_pred1) / a_hat.sqrt()\n",
    "                x0_hat = x0_hat.permute(0,3,2,1)\n",
    "            s = x0_hat\n",
    "        \n",
    "        noise_loss, player_loss = model(target, cond_info=cond_H, self_cond=s)\n",
    "        loss = noise_loss + player_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_noise_loss += noise_loss.item()\n",
    "        train_player_loss += player_loss.item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    num_batches = len(train_dataloader)\n",
    "    \n",
    "    avg_noise_loss = train_noise_loss / num_batches\n",
    "    avg_player_loss = train_player_loss / num_batches\n",
    "    avg_train_loss = train_loss / num_batches\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_noise_loss = 0\n",
    "    val_player_loss = 0\n",
    "    val_total_loss = 0\n",
    "    total_val_samples = 0\n",
    "    \n",
    "    all_val_ade, all_val_fde = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            B, T, _ = batch[\"condition\"].shape\n",
    "            target = batch[\"target\"].to(device).view(B, T, 11, 2)\n",
    "            H = graph_encoder(batch[\"graph\"].to(device))\n",
    "            cond_H = H.unsqueeze(-1).unsqueeze(-1).expand(-1, H.size(1), 11, T)\n",
    "            \n",
    "            # Compute loss without Self-Conditioning\n",
    "            s = torch.zeros_like(target)\n",
    "            noise_loss, player_loss = model(target, cond_info=cond_H, self_cond=s)\n",
    "            loss = noise_loss + player_loss\n",
    "            \n",
    "            val_noise_loss += noise_loss.item() * B\n",
    "            val_player_loss += player_loss.item() * B\n",
    "            val_total_loss += loss.item() * B\n",
    "            \n",
    "            total_val_samples += B\n",
    "        \n",
    "    avg_val_noise  = val_noise_loss / total_val_samples\n",
    "    avg_val_player = val_player_loss / total_val_samples\n",
    "    avg_val_loss   = val_total_loss / total_val_samples\n",
    "            \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        flag = True\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_state_dict = model.state_dict()\n",
    "    \n",
    "    tqdm.write(f\"[Epoch {epoch}]\\nCost: {avg_train_loss:.6f} | Noise Loss: {avg_noise_loss:.6f} | \"\n",
    "               f\"Player Loss: {avg_player_loss:.6f} | LR: {scheduler.get_last_lr()[0]:.6f}\\n\"\n",
    "               f\"Val Loss: {avg_val_loss:.6f} | Noise: {avg_val_noise:.6f} | Player: {avg_val_player:.6f} | \"\n",
    "               f\"Model Update: {'Update' if flag else 'No Update'}\")\n",
    "    flag = False\n",
    "    \n",
    "# 4-1. Plot learning_curve\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train & Validation Loss, 500 steps, 128 channels, 128 embedding dim, 4 heads, 6 layers')\n",
    "plt.legend()\n",
    "plt.ylim(0, 0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('results/diffusion_lr_curve.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Inference (Best-of-N Sampling) & Metrics\n",
    "model.load_state_dict(best_state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_val_ade, all_val_fde = [], []\n",
    "visualize_samples = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader, desc=\"Val Inference\"):\n",
    "        B, T, _ = batch[\"condition\"].shape\n",
    "        target = batch[\"target\"].to(device).view(B, T, 11, 2)\n",
    "        H = graph_encoder(batch[\"graph\"].to(device))\n",
    "        cond_H = H.unsqueeze(-1).unsqueeze(-1).expand(-1, H.size(1), 11, T)\n",
    "\n",
    "        # Best-of-N trajectory 생성\n",
    "        generated = model.generate(\n",
    "            shape=target.shape,\n",
    "            cond_info=cond_H,\n",
    "            num_samples=num_samples  # 이전에 설정한 N값 사용\n",
    "        )  # [N, B, T, 11, 2]\n",
    "\n",
    "        # Denormalize (pitch_scale 복원)\n",
    "        scales = torch.tensor(batch[\"pitch_scale\"], device=device, dtype=torch.float32)  # [B,2]\n",
    "        scales = scales.view(1, B, 1, 1, 2)\n",
    "        generated = generated * scales\n",
    "        target_gt = target.unsqueeze(0) * scales\n",
    "\n",
    "        # Best trajectory 선택\n",
    "        ade_per_sample = ((generated - target_gt)**2).sum(-1).sqrt().mean((2,3))  # [N, B]\n",
    "        best_idx = ade_per_sample.argmin(dim=0)                                 # [B]\n",
    "        best_pred = generated[best_idx, torch.arange(B)]                       # [B, T, 11, 2]\n",
    "\n",
    "        # ADE/FDE 계산\n",
    "        ade = ((best_pred - target)**2).sum(-1).sqrt().mean((1,2))            # [B]\n",
    "        fde = ((best_pred[:, -1] - target[:, -1])**2).sum(-1).sqrt()          # [B]\n",
    "\n",
    "        all_val_ade.extend(ade.cpu().numpy())\n",
    "        all_val_fde.extend(fde.cpu().numpy())\n",
    "\n",
    "        for i in range(min(B, visualize_samples)):\n",
    "            # 데이터 준비\n",
    "            # others: shape (T, 12, 2) — 11 공격수 + 1 공\n",
    "            others = batch[\"other\"][i].view(T, 12, 2).cpu().numpy()\n",
    "            gt    = target[i].cpu().numpy()    # (T, 11, 2)\n",
    "            pred  = best_pred[i].cpu().numpy()  # (T, 11, 2)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            plot_trajectories_on_pitch(\n",
    "                others=others,\n",
    "                target_defenders=gt,\n",
    "                pred_defenders=pred,\n",
    "                player_idx=None,   # 모든 수비수를 함께 그림\n",
    "                annotate=True,     # 번호 라벨 표시\n",
    "                ax=ax\n",
    "            )\n",
    "            ax.set_title(f\"Val Sample {i} — Best-of-{num_samples}\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            os.makedirs(\"results/val_full_plots\", exist_ok=True)\n",
    "            fig.savefig(f\"results/val_full_plots/val_sample_{i:02d}_full.png\", dpi=150)\n",
    "            plt.close(fig)\n",
    "\n",
    "        break  # 첫 배치에 대해서만 시각화\n",
    "\n",
    "# 전체 평균 값 출력\n",
    "avg_val_ade = np.mean(all_val_ade)\n",
    "avg_val_fde = np.mean(all_val_fde)\n",
    "print(f\"[Validation - Best of {num_samples}] ADE: {avg_val_ade:.4f} | FDE: {avg_val_fde:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inference (Best-of-N Sampling) & Visualization\n",
    "model.load_state_dict(best_state_dict)\n",
    "model.eval()\n",
    "all_ade, all_fde = [], []\n",
    "visualize_samples = 5\n",
    "visualization_done = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Inference\"):\n",
    "        B, T, _ = batch[\"condition\"].shape\n",
    "        target = batch[\"target\"].to(device).view(B, T, 11, 2)      \n",
    "        H = graph_encoder(batch[\"graph\"].to(device))\n",
    "        cond_H = H.unsqueeze(-1).unsqueeze(-1).expand(-1, H.size(1), 11, T)\n",
    "\n",
    "        generated = model.generate(shape=target.shape, cond_info=cond_H, num_samples=num_samples)  # [N, B, T, 11, 2]\n",
    "\n",
    "        # Denormalize\n",
    "        scales = torch.tensor(batch[\"pitch_scale\"],device=device, dtype=torch.float32)           # [B,2]\n",
    "        scales = scales.view(1, B, 1, 1, 2)\n",
    "        \n",
    "        generated = generated * scales\n",
    "        target_gt = target.unsqueeze(0) * scales\n",
    "        \n",
    "        # generated/[0,1] → [−1,1] → 실제[m]\n",
    "        # generated[..., 0] = (generated[..., 0] - 0.5) * 2 * x_scales\n",
    "        # generated[..., 1] = (generated[..., 1] - 0.5) * 2 * y_scales\n",
    "\n",
    "        # # target도 동일하게 복원\n",
    "        # target[..., 0] = (target[..., 0] - 0.5) * 2 * x_scales\n",
    "        # target[..., 1] = (target[..., 1] - 0.5) * 2 * y_scales\n",
    "\n",
    "        ade = ((generated - target_gt) ** 2).sum(-1).sqrt().mean((2, 3))  # [N, B]\n",
    "        best_idx = ade.argmin(dim=0)                                    # [B]\n",
    "        best_pred = generated[best_idx, torch.arange(B)]                # [B, T, 11, 2]\n",
    "\n",
    "        ade_final = ((best_pred - target) ** 2).sum(-1).sqrt().mean((1, 2))                               # [B]\n",
    "        fde_final = ((best_pred[:, -1] - target[:, -1]) ** 2).sum(-1).sqrt()                               # [B]\n",
    "\n",
    "        all_ade.extend(ade_final.cpu().numpy())\n",
    "        all_fde.extend(fde_final.cpu().numpy())\n",
    "        \n",
    "\n",
    "        if not visualization_done:\n",
    "            os.makedirs(\"results\", exist_ok=True)\n",
    "            for i in range(min(B, visualize_samples)):\n",
    "                others = batch[\"other\"][i].view(-1,12,2).cpu().numpy()\n",
    "                target_ = target[i].cpu().numpy()   # (T,11,2)\n",
    "                pred_ = best_pred[i].cpu().numpy()     # (T,11,2)\n",
    "                \n",
    "                save_path = f\"results/Diff_sample_{i:02d}.png\"\n",
    "                \n",
    "                os.makedirs('results/player_trajs', exist_ok=True)\n",
    "                for p in range(11):\n",
    "                    save_path = f'results/player_trajs/sample{i:02d}_def{p:02d}.png'\n",
    "                    plot_trajectories_on_pitch(others, target_, pred_, player_idx=p, save_path=save_path)\n",
    "            visualization_done = True\n",
    "\n",
    "avg_ade = np.mean(all_ade)\n",
    "avg_fde = np.mean(all_fde)\n",
    "print(f\"[Inference - Best of {num_samples}] ADE: {avg_ade:.4f} | FDE: {avg_fde:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoccerTraj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
